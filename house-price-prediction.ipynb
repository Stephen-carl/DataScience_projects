{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8031584,"sourceType":"datasetVersion","datasetId":4734060}],"dockerImageVersionId":30746,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-13T12:34:14.172555Z","iopub.execute_input":"2024-08-13T12:34:14.173177Z","iopub.status.idle":"2024-08-13T12:34:14.634712Z","shell.execute_reply.started":"2024-08-13T12:34:14.173121Z","shell.execute_reply":"2024-08-13T12:34:14.633540Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Note: This is my very first Data Analytics and Science project, I know i am still rusty.","metadata":{}},{"cell_type":"markdown","source":"# Predicting House Prices\nThis is a simple analysis and prediction of house prices. We will find out which particular factor affects the price of house.\nWe will check by:\n- Location\n- Size (area of space occupied)\n- Year built\n- All the parameters","metadata":{}},{"cell_type":"markdown","source":"# **Imports**","metadata":{}},{"cell_type":"code","source":"# getting the necessary imports\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\n# transformers and predictor\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.linear_model import Ridge\nfrom sklearn.pipeline import make_pipeline\nfrom category_encoders import OneHotEncoder\n# performance metrics\nfrom sklearn.metrics import mean_absolute_error\n# model selection for train and test data\nfrom sklearn.model_selection import train_test_split\n","metadata":{"execution":{"iopub.status.busy":"2024-08-13T12:34:14.640270Z","iopub.execute_input":"2024-08-13T12:34:14.640692Z","iopub.status.idle":"2024-08-13T12:34:15.499523Z","shell.execute_reply.started":"2024-08-13T12:34:14.640651Z","shell.execute_reply":"2024-08-13T12:34:15.498289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Reading and Exploring the Data\nI am still working on my story telling.","metadata":{}},{"cell_type":"code","source":"# read the csv file and see the information for each columns\ndata = pd.read_csv('/kaggle/input/housing-price-dataset/Housing.csv')\ndata.info()","metadata":{"execution":{"iopub.status.busy":"2024-08-13T12:34:15.500852Z","iopub.execute_input":"2024-08-13T12:34:15.501361Z","iopub.status.idle":"2024-08-13T12:34:15.598107Z","shell.execute_reply.started":"2024-08-13T12:34:15.501329Z","shell.execute_reply":"2024-08-13T12:34:15.596961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-13T12:34:15.601134Z","iopub.execute_input":"2024-08-13T12:34:15.601476Z","iopub.status.idle":"2024-08-13T12:34:15.632796Z","shell.execute_reply.started":"2024-08-13T12:34:15.601446Z","shell.execute_reply":"2024-08-13T12:34:15.631502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# let's check if there's any with nan values\ndata.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2024-08-13T12:34:15.634103Z","iopub.execute_input":"2024-08-13T12:34:15.634423Z","iopub.status.idle":"2024-08-13T12:34:15.648371Z","shell.execute_reply.started":"2024-08-13T12:34:15.634396Z","shell.execute_reply":"2024-08-13T12:34:15.646984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So we have a clean dataset with no nan value. \nLet's check the shape. i.e No. of columns and rows","metadata":{}},{"cell_type":"code","source":"data.shape","metadata":{"execution":{"iopub.status.busy":"2024-08-13T12:34:15.650080Z","iopub.execute_input":"2024-08-13T12:34:15.651347Z","iopub.status.idle":"2024-08-13T12:34:15.663864Z","shell.execute_reply.started":"2024-08-13T12:34:15.651300Z","shell.execute_reply":"2024-08-13T12:34:15.662037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We have 21,613 rows and 21 columns","metadata":{}},{"cell_type":"markdown","source":"**Let's view:**\n- Price relative to the number of rooms\n- Price relative to size\n- Prices of houses based on year\n- cluster of the houses and their price","metadata":{}},{"cell_type":"code","source":"# no of unique values of bedrooms\ndata['bedrooms'].unique()","metadata":{"execution":{"iopub.status.busy":"2024-08-13T12:34:15.666468Z","iopub.execute_input":"2024-08-13T12:34:15.666947Z","iopub.status.idle":"2024-08-13T12:34:15.679894Z","shell.execute_reply.started":"2024-08-13T12:34:15.666903Z","shell.execute_reply":"2024-08-13T12:34:15.678070Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# price relative to the number of rooms\nsns.barplot(x = data.bedrooms, y = data.price)\nplt.ylabel('Price in Millions')","metadata":{"execution":{"iopub.status.busy":"2024-08-13T12:34:15.682010Z","iopub.execute_input":"2024-08-13T12:34:15.682469Z","iopub.status.idle":"2024-08-13T12:34:16.545203Z","shell.execute_reply.started":"2024-08-13T12:34:15.682425Z","shell.execute_reply":"2024-08-13T12:34:16.544009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=[15,5])\nsns.scatterplot(data, x = 'sqft_living', y = 'price', hue = 'yr_built')\n","metadata":{"execution":{"iopub.status.busy":"2024-08-13T12:34:16.547096Z","iopub.execute_input":"2024-08-13T12:34:16.547415Z","iopub.status.idle":"2024-08-13T12:34:18.983353Z","shell.execute_reply.started":"2024-08-13T12:34:16.547388Z","shell.execute_reply":"2024-08-13T12:34:18.982032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Prices of houses based on year\n# convert the date to pandas date\ndata['date'] = pd.to_datetime(data['date'])\n# to make it show the date with only month\nresampled_df = data.resample(\"M\", on=\"date\").mean().reset_index()\n\n# i only want to visulaize data based on month data\nplt.figure(figsize=[12,5])\nsns.lineplot(data = resampled_df, x = 'date', y = 'price', c= 'red', marker = 'o')\nplt.xlabel(\"Date\")\nplt.ylabel(\"Price\")\nplt.title(\"Average Price Per Mounth\")","metadata":{"execution":{"iopub.status.busy":"2024-08-13T12:34:18.985010Z","iopub.execute_input":"2024-08-13T12:34:18.985782Z","iopub.status.idle":"2024-08-13T12:34:19.393250Z","shell.execute_reply.started":"2024-08-13T12:34:18.985740Z","shell.execute_reply":"2024-08-13T12:34:19.392106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Analysis and question answering**\n- ","metadata":{}},{"cell_type":"code","source":"# knowing the average price for each no. of house bedroom\ndata.groupby('bedrooms')['price'].mean()","metadata":{"execution":{"iopub.status.busy":"2024-08-13T12:34:19.394669Z","iopub.execute_input":"2024-08-13T12:34:19.395000Z","iopub.status.idle":"2024-08-13T12:34:19.406141Z","shell.execute_reply.started":"2024-08-13T12:34:19.394970Z","shell.execute_reply":"2024-08-13T12:34:19.404879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Processing\nThis will involve\n- data cleaning/wrangling\n- Checking and removing\n    - Outliers\n    - Correlations/ removing unncessary features\n    - columns with low and high cardinality\n- Separate the train from test data, and the feature and target data","metadata":{}},{"cell_type":"code","source":"# I will like to subset my data to just house lesser than 1.5million\nmask_price = data['price'] < 1500000\n# removing outliers by only taking data between the 0.1 and0.9 quartile\nlow, high= data['price'].quantile([0.1,0.9])\nmask_card = data['price'].between(low, high)\ndata = data[mask_price & mask_card]\ndata.shape","metadata":{"execution":{"iopub.status.busy":"2024-08-13T12:34:19.407691Z","iopub.execute_input":"2024-08-13T12:34:19.408160Z","iopub.status.idle":"2024-08-13T12:34:19.423913Z","shell.execute_reply.started":"2024-08-13T12:34:19.408121Z","shell.execute_reply":"2024-08-13T12:34:19.422568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# drop correlating columns\nplt.figure(figsize = (15,8))\nsns.heatmap(data.corr())","metadata":{"execution":{"iopub.status.busy":"2024-08-13T12:34:19.428873Z","iopub.execute_input":"2024-08-13T12:34:19.429282Z","iopub.status.idle":"2024-08-13T12:34:20.172155Z","shell.execute_reply.started":"2024-08-13T12:34:19.429250Z","shell.execute_reply":"2024-08-13T12:34:20.171068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It can be seen that sqft_lot, sqft_lot15, sqft_living15, sqft_living and sqft_above, all have correlation. But for this analysis, i am only going to keep sqft_living.","metadata":{}},{"cell_type":"code","source":"# before dropping unneccesary colunmns. Let's checking for columns with low and high cardinality\ndata.nunique()","metadata":{"execution":{"iopub.status.busy":"2024-08-13T12:34:20.173542Z","iopub.execute_input":"2024-08-13T12:34:20.173892Z","iopub.status.idle":"2024-08-13T12:34:20.192138Z","shell.execute_reply.started":"2024-08-13T12:34:20.173863Z","shell.execute_reply":"2024-08-13T12:34:20.191011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It can be seen that columns like id (all items are very unique, thus high cardinality), sqft_lot, sqft_lot15\nthen, floors, waterfrint, view, condition, grade.\nWe have to drop those columns","metadata":{}},{"cell_type":"code","source":"data.drop(columns = ['id', 'waterfront', 'view', 'condition', 'grade', 'sqft_lot', 'sqft_lot15', 'floors'], inplace = True)\ndata.shape\ndata.info()","metadata":{"execution":{"iopub.status.busy":"2024-08-13T12:35:04.225964Z","iopub.execute_input":"2024-08-13T12:35:04.226368Z","iopub.status.idle":"2024-08-13T12:35:04.241309Z","shell.execute_reply.started":"2024-08-13T12:35:04.226337Z","shell.execute_reply":"2024-08-13T12:35:04.240085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# drop the correlators  and other unnecessary columns\ndata.drop(columns = ['sqft_above', 'sqft_basement', 'sqft_living15', 'zipcode', 'yr_renovated', 'bathrooms', 'date'],inplace = True)","metadata":{"execution":{"iopub.status.busy":"2024-08-13T12:34:20.209967Z","iopub.execute_input":"2024-08-13T12:34:20.210907Z","iopub.status.idle":"2024-08-13T12:34:20.217613Z","shell.execute_reply.started":"2024-08-13T12:34:20.210850Z","shell.execute_reply":"2024-08-13T12:34:20.216374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"execution":{"iopub.status.busy":"2024-08-13T12:35:09.024820Z","iopub.execute_input":"2024-08-13T12:35:09.025244Z","iopub.status.idle":"2024-08-13T12:35:09.037520Z","shell.execute_reply.started":"2024-08-13T12:35:09.025209Z","shell.execute_reply":"2024-08-13T12:35:09.036313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Train and Test, Feature and Target Data**\n-","metadata":{}},{"cell_type":"code","source":"# I will first get the feature and target data out\n# Since i will be predicting for different scenrios, the feature variables will be specific to its role but the target woun't\n\ntarget = 'price'\ny_train = data[target]\n\nyear = ['yr_built']\nyearFeature = data[year]\n\nsqft = ['sqft_living']\nsqftFeature = data[sqft]\n\nbedroom = ['bedrooms']\nbedroomFeature = data[bedroom]\n\nlocation = ['lat', 'long']\nlocationFeature = data[location]\n\nall = ['bedrooms', 'sqft_living', 'yr_built', 'lat', 'long']\nallFeature = data[all]\nsqftFeature.shape","metadata":{"execution":{"iopub.status.busy":"2024-08-13T12:46:06.125205Z","iopub.execute_input":"2024-08-13T12:46:06.125624Z","iopub.status.idle":"2024-08-13T12:46:06.140453Z","shell.execute_reply.started":"2024-08-13T12:46:06.125588Z","shell.execute_reply":"2024-08-13T12:46:06.139245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# then its time to shuffle and split\nallFeatTrain, allFeatTest, allTargetTrain, allTargetTest = train_test_split(allFeature, y_train, test_size = 0.3, random_state  = 42,shuffle = True)\nyearFeatTrain, yearFeatTest, yearTargetTrain, yearTargetTest = train_test_split(yearFeature, y_train, test_size = 0.3, random_state  = 42,shuffle = True)\nsqftFeatTrain, sqftFeatTest, sqftTargetTrain, sqftTargetTest = train_test_split(sqftFeature, y_train, test_size = 0.3, random_state  = 42,shuffle = True)\nbedroomFeatTrain, bedroomFeatTest, bedroomTargetTrain, bedroomTargetTest = train_test_split(bedroomFeature, y_train, test_size = 0.3, random_state  = 42,shuffle = True)\nlocationFeatTrain, locationFeatTest, locationTargetTrain, locationTargetTest = train_test_split(locationFeature, y_train, test_size = 0.3, random_state  = 42,shuffle = True)\n\nyearTargetTest.shape","metadata":{"execution":{"iopub.status.busy":"2024-08-13T12:59:57.178951Z","iopub.execute_input":"2024-08-13T12:59:57.179373Z","iopub.status.idle":"2024-08-13T12:59:57.205330Z","shell.execute_reply.started":"2024-08-13T12:59:57.179341Z","shell.execute_reply":"2024-08-13T12:59:57.204335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Build Model","metadata":{}},{"cell_type":"markdown","source":"**The Baseline model**\n-","metadata":{}},{"cell_type":"code","source":"# get the mean of the target data\ny_mean = y_train.mean()\n# let the mean be a list with the length of the target data\ny_base = [y_mean] * len(y_train)\n# as a metric measurement, i will use MAE\ny_baseline_metric = mean_absolute_error(y_train, y_base).round(2)\nprint(f'The mean absolute error is {y_baseline_metric}')","metadata":{"execution":{"iopub.status.busy":"2024-08-13T14:34:03.443185Z","iopub.execute_input":"2024-08-13T14:34:03.443591Z","iopub.status.idle":"2024-08-13T14:34:03.454658Z","shell.execute_reply.started":"2024-08-13T14:34:03.443554Z","shell.execute_reply":"2024-08-13T14:34:03.453460Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Define Model, Fit and Predict**\n-","metadata":{}},{"cell_type":"code","source":"modelPipeline = make_pipeline(\n    # i will use these transformers just in case of an oversight\n    #OneHotEncoder(use_cat_names=True),\n    SimpleImputer(), \n    # predictor\n    Ridge()\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-13T13:44:02.768621Z","iopub.execute_input":"2024-08-13T13:44:02.769285Z","iopub.status.idle":"2024-08-13T13:44:02.774130Z","shell.execute_reply.started":"2024-08-13T13:44:02.769250Z","shell.execute_reply":"2024-08-13T13:44:02.773009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'{allFeatTrain.shape}, {yearTargetTrain.shape}')","metadata":{"execution":{"iopub.status.busy":"2024-08-13T13:48:51.458871Z","iopub.execute_input":"2024-08-13T13:48:51.460005Z","iopub.status.idle":"2024-08-13T13:48:51.466431Z","shell.execute_reply.started":"2024-08-13T13:48:51.459949Z","shell.execute_reply":"2024-08-13T13:48:51.465076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This is not a recommended approach when dealing multiple factors than this. A for loop is better to split train and test data\nfeatures = [yearFeatTrain, sqftFeatTrain, bedroomFeatTrain, locationFeatTrain, allFeatTrain]\ntheTargets = [yearTargetTrain, sqftTargetTrain, bedroomTargetTrain, locationTargetTrain, allTargetTrain]\ntestfeatures = [yearFeatTest, sqftFeatTest, bedroomFeatTest, locationFeatTest, allFeatTest] \ntestTarget = [yearTargetTest, sqftTargetTest, bedroomTargetTest, locationTargetTest, allTargetTest] \nresult = {}\n\n#loop through the feature to fit the model and predict \nfor feature, featureTest, price, targetTest  in zip(features, testfeatures, theTargets, testTarget):\n    # fit the model\n    modelPipeline.fit(feature, price)\n    \n    #Store the fitted model into a list\n    #modelPipeline[feature] = modelPipeline\n    \n    #predict using the test data\n    price_pred = modelPipeline.predict(featureTest)\n    \n    #get the MAE\n    modelMAE = mean_absolute_error(targetTest, price_pred)\n    \n    # store the result\n    result = {'MAE' : modelMAE}\n\n# lets print the result\nfor feature in features:\n    print(f'MAE: {result[\"MAE\"]}')\n    ","metadata":{"execution":{"iopub.status.busy":"2024-08-13T13:55:39.175202Z","iopub.execute_input":"2024-08-13T13:55:39.175593Z","iopub.status.idle":"2024-08-13T13:55:39.247323Z","shell.execute_reply.started":"2024-08-13T13:55:39.175565Z","shell.execute_reply":"2024-08-13T13:55:39.245826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# let me try this\nmodelPipeline.fit(allFeatTrain, allTargetTrain)\nall_pred = modelPipeline.predict(allFeatTest)","metadata":{"execution":{"iopub.status.busy":"2024-08-13T14:30:04.467826Z","iopub.execute_input":"2024-08-13T14:30:04.468788Z","iopub.status.idle":"2024-08-13T14:30:04.487469Z","shell.execute_reply.started":"2024-08-13T14:30:04.468745Z","shell.execute_reply":"2024-08-13T14:30:04.486038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MAE = mean_absolute_error(allTargetTest, all_pred).round(2)","metadata":{"execution":{"iopub.status.busy":"2024-08-13T14:31:04.101708Z","iopub.execute_input":"2024-08-13T14:31:04.102114Z","iopub.status.idle":"2024-08-13T14:31:04.108167Z","shell.execute_reply.started":"2024-08-13T14:31:04.102082Z","shell.execute_reply":"2024-08-13T14:31:04.106949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MAE","metadata":{"execution":{"iopub.status.busy":"2024-08-13T14:31:05.805234Z","iopub.execute_input":"2024-08-13T14:31:05.805630Z","iopub.status.idle":"2024-08-13T14:31:05.812974Z","shell.execute_reply.started":"2024-08-13T14:31:05.805599Z","shell.execute_reply":"2024-08-13T14:31:05.811617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"modelPipeline.fit(yearFeatTrain, yearTargetTrain)\nyear_pred = modelPipeline.predict(yearFeatTest)\nyearMAE = mean_absolute_error(yearTargetTest, year_pred).round(2)\nyearMAE","metadata":{"execution":{"iopub.status.busy":"2024-08-13T14:35:32.552413Z","iopub.execute_input":"2024-08-13T14:35:32.552817Z","iopub.status.idle":"2024-08-13T14:35:32.573378Z","shell.execute_reply.started":"2024-08-13T14:35:32.552779Z","shell.execute_reply":"2024-08-13T14:35:32.571651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"modelPipeline.fit(sqftFeatTrain, sqftTargetTrain)\nsqft_pred = modelPipeline.predict(sqftFeatTest)\nsqftMAE = mean_absolute_error(sqftTargetTest, sqft_pred).round(2)\nsqftMAE","metadata":{"execution":{"iopub.status.busy":"2024-08-13T14:47:20.479767Z","iopub.execute_input":"2024-08-13T14:47:20.480197Z","iopub.status.idle":"2024-08-13T14:47:20.497647Z","shell.execute_reply.started":"2024-08-13T14:47:20.480167Z","shell.execute_reply":"2024-08-13T14:47:20.496098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"modelPipeline.fit(bedroomFeatTrain, bedroomTargetTrain)\nbed_pred = modelPipeline.predict(bedroomFeatTest)\nbedMAE = mean_absolute_error(bedroomTargetTest, bed_pred).round(2)\nbedMAE","metadata":{"execution":{"iopub.status.busy":"2024-08-13T14:39:58.183147Z","iopub.execute_input":"2024-08-13T14:39:58.183509Z","iopub.status.idle":"2024-08-13T14:39:58.210073Z","shell.execute_reply.started":"2024-08-13T14:39:58.183482Z","shell.execute_reply":"2024-08-13T14:39:58.208296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"modelPipeline.fit(locationFeatTrain, locationTargetTrain)\nlocation_pred = modelPipeline.predict(locationFeatTest)\nlocationMAE = mean_absolute_error(locationTargetTest, location_pred).round(2)\nlocationMAE","metadata":{"execution":{"iopub.status.busy":"2024-08-13T14:41:21.584880Z","iopub.execute_input":"2024-08-13T14:41:21.585961Z","iopub.status.idle":"2024-08-13T14:41:21.608478Z","shell.execute_reply.started":"2024-08-13T14:41:21.585921Z","shell.execute_reply":"2024-08-13T14:41:21.607055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}